{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f731558d-0760-42af-935c-b5b8187d8c64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:26:14.332653Z",
     "iopub.status.busy": "2025-05-30T21:26:14.331663Z",
     "iopub.status.idle": "2025-05-30T21:26:16.686675Z",
     "shell.execute_reply": "2025-05-30T21:26:16.685798Z",
     "shell.execute_reply.started": "2025-05-30T21:26:14.332618Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e1601-73e9-4c88-8006-d555646840e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:26:16.689901Z",
     "iopub.status.busy": "2025-05-30T21:26:16.688412Z",
     "iopub.status.idle": "2025-05-30T21:26:24.486123Z",
     "shell.execute_reply": "2025-05-30T21:26:24.485279Z",
     "shell.execute_reply.started": "2025-05-30T21:26:16.689862Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2025-05-30 21:26:20.035605: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-30 21:26:20.087724: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-30 21:26:21.333817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import Pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631ba06-d47f-4658-a32f-16ddba28667c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:26:24.488308Z",
     "iopub.status.busy": "2025-05-30T21:26:24.487169Z",
     "iopub.status.idle": "2025-05-30T21:26:24.543720Z",
     "shell.execute_reply": "2025-05-30T21:26:24.542846Z",
     "shell.execute_reply.started": "2025-05-30T21:26:24.488275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = '/home/jupyter/datasphere/project/rugec/data/RULEC-GEC.test.tsv'\n",
    "test = '/home/jupyter/datasphere/project/rugec/data/RULEC-GEC.dev.tsv'\n",
    "rulec_test = pd.read_csv(test, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0fc65-1a35-4484-b09a-7d8c845c8b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:26:24.546414Z",
     "iopub.status.busy": "2025-05-30T21:26:24.545395Z",
     "iopub.status.idle": "2025-05-30T21:26:24.568617Z",
     "shell.execute_reply": "2025-05-30T21:26:24.567793Z",
     "shell.execute_reply.started": "2025-05-30T21:26:24.546376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ds = Dataset.from_dict({'corrupt_sent':rulec_test['corrupt_sent'],'correct_sent' : rulec_test['correct_sent']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae8624c-bbb8-4819-bc62-ed0369281115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:26:24.570807Z",
     "iopub.status.busy": "2025-05-30T21:26:24.569730Z",
     "iopub.status.idle": "2025-05-30T21:26:24.588729Z",
     "shell.execute_reply": "2025-05-30T21:26:24.587896Z",
     "shell.execute_reply.started": "2025-05-30T21:26:24.570767Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'corrupt_sent': 'Экскурсия прошла великолепно , Владимир Анатольевич просто изумительный экскурсовод .', 'correct_sent': 'Экскурсия прошла великолепно , Владимир Анатольевич просто изумительный экскурсовод .'}\n"
     ]
    }
   ],
   "source": [
    "for i in test_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2de558-81a9-4996-bb39-64f89d807bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:26:39.986072Z",
     "iopub.status.busy": "2025-05-30T21:26:39.984867Z",
     "iopub.status.idle": "2025-05-30T21:27:16.682151Z",
     "shell.execute_reply": "2025-05-30T21:27:16.681247Z",
     "shell.execute_reply.started": "2025-05-30T21:26:39.986022Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "# name = 'mika5883/pretrain_rugec_msu'\n",
    "# model_name = 'mika5883/gec_t5_dpo'\n",
    "# model_name = 'mika5883/gec_t5_dpo_A_v1'\n",
    "# name = 'mika5883/finetune_rugec_msu'\n",
    "# model_name = 'mika5883/ft_rugec_A'\n",
    "# model_name = 'mika5883/Full_Train_Dev'\n",
    "# model_name = 'mika5883/gec_t5_dpo_A_v2'\n",
    "# model_name = 'mika5883/RULEC_Tr_Dev_NVP5000'\n",
    "model_name = 'mika5883/finetune_rugec_Ae' \n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07833c1-e7a7-40a1-af6a-e5a5e289000d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T12:42:00.358544Z",
     "iopub.status.busy": "2025-05-30T12:42:00.357738Z",
     "iopub.status.idle": "2025-05-30T12:42:00.396663Z",
     "shell.execute_reply": "2025-05-30T12:42:00.395883Z",
     "shell.execute_reply.started": "2025-05-30T12:42:00.358509Z"
    }
   },
   "outputs": [],
   "source": [
    "# can try sampling diverse outputs for some purposes but it doesn't give the best results on its own.\n",
    "\n",
    "\n",
    "# def enable_dropout(model):\n",
    "#     \"\"\"Function to enable the dropout layers during test-time\"\"\"\n",
    "#     for module in model.modules():\n",
    "#         if isinstance(module, torch.nn.Dropout):\n",
    "#             module.train()\n",
    "# model.eval()          \n",
    "# enable_dropout(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970e6b7-3fa3-46eb-86bd-9309f9cddf5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:27:16.684686Z",
     "iopub.status.busy": "2025-05-30T21:27:16.683751Z",
     "iopub.status.idle": "2025-05-30T21:27:16.696335Z",
     "shell.execute_reply": "2025-05-30T21:27:16.695510Z",
     "shell.execute_reply.started": "2025-05-30T21:27:16.684648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples, prefix='grammar: '):\n",
    "    # inputs = [f'grammar: {each}' for each in examples['corrupt_sent']]\n",
    "    inputs = [f'{prefix}{each}' for each in examples]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    model_inputs['inputs'] = inputs\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a2df14-fd7c-4165-ac04-e990299bf07c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:27:16.726103Z",
     "iopub.status.busy": "2025-05-30T21:27:16.725077Z",
     "iopub.status.idle": "2025-05-30T21:27:16.737875Z",
     "shell.execute_reply": "2025-05-30T21:27:16.737039Z",
     "shell.execute_reply.started": "2025-05-30T21:27:16.726068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"maybe_arg\" in kwargs:\n",
    "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, inputs, maybe_arg=2):\n",
    "        if isinstance(inputs, str):\n",
    "            inputs = [inputs]\n",
    "        model_inputs = tokenize_function(inputs).input_ids.to(self.device)\n",
    "        return {\"inputs\": model_inputs}\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        # with torch.no_grad():\n",
    "        outputs = self.model.generate(\n",
    "            **model_inputs, \n",
    "            max_new_tokens=128, \n",
    "            num_return_sequences=6, \n",
    "            num_beams=6,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        return tokenizer.batch_decode(\n",
    "            model_outputs, \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.postprocess(self._forward(self.preprocess(inputs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92873ace-f93c-4521-9fd4-47d8b9c36393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:27:16.740205Z",
     "iopub.status.busy": "2025-05-30T21:27:16.738932Z",
     "iopub.status.idle": "2025-05-30T21:27:23.963053Z",
     "shell.execute_reply": "2025-05-30T21:27:23.962193Z",
     "shell.execute_reply.started": "2025-05-30T21:27:16.740162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "gram = MyPipeline(model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d3bfe2a-3faa-4bc4-ac6e-fec0b8b00b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:31:46.000460Z",
     "iopub.status.busy": "2025-05-30T21:31:45.999561Z",
     "iopub.status.idle": "2025-05-30T21:31:46.366823Z",
     "shell.execute_reply": "2025-05-30T21:31:46.365949Z",
     "shell.execute_reply.started": "2025-05-30T21:31:46.000421Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[': Многие люди ошибочно полагают , что земле 2000 лет .',\n",
       " 'Многие люди ошибочно полагают , что земле 2000 лет .',\n",
       " 'Многие люди ошибочно полагают , что земле 2000 лет .',\n",
       " 'Мнагие люди ошибочно полагают , что земле 2000 лет .',\n",
       " 'Многим людям ошибочно полагают , что земле 2000 лет .',\n",
       " 'Некоторые люди ошибочно полагают , что земле 2000 лет .']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = gram.preprocess('grammar: Мнагие люди ашибочно пологают , что земле 2000 лет .')\n",
    "outs = gram.forward(pr)\n",
    "gram.postprocess(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60846a96-3fd8-4e6f-b7be-cab3dea5e3b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:27:23.977226Z",
     "iopub.status.busy": "2025-05-30T21:27:23.975733Z",
     "iopub.status.idle": "2025-05-30T21:31:45.998620Z",
     "shell.execute_reply": "2025-05-30T21:31:45.997664Z",
     "shell.execute_reply.started": "2025-05-30T21:27:23.977170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Correcting: 100%|██████████| 40/40 [04:21<00:00,  6.54s/it]\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "corrected_sents = []\n",
    "batch_size = 64\n",
    "total_count = len(test_ds)\n",
    "chunks = ceil(total_count / batch_size)\n",
    "\n",
    "def div(outs, n=6):\n",
    "    #grouping corrections per sentence since len(outputs) == batch_size * num_return_sequences\n",
    "    return [outs[i:i+n] for i in range(0, len(outs), n)]\n",
    "\n",
    "for i in tqdm.tqdm(range(chunks), desc=\"Correcting\"):\n",
    "    batch = KeyDataset(test_ds, 'corrupt_sent')[i*batch_size:(i+1)*batch_size]\n",
    "    outputs = gram(batch)\n",
    "    corrected_sents.append(div(outputs))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "076e47a5-db1e-4242-9f31-b071289a48c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:31:46.369678Z",
     "iopub.status.busy": "2025-05-30T21:31:46.368923Z",
     "iopub.status.idle": "2025-05-30T21:31:46.381754Z",
     "shell.execute_reply": "2025-05-30T21:31:46.381001Z",
     "shell.execute_reply.started": "2025-05-30T21:31:46.369642Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cors = [b for a in corrected_sents for b in a]\n",
    "len(cors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada85501-3985-4620-abff-263e14efaa74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:31:46.383660Z",
     "iopub.status.busy": "2025-05-30T21:31:46.382716Z",
     "iopub.status.idle": "2025-05-30T21:31:46.510963Z",
     "shell.execute_reply": "2025-05-30T21:31:46.510214Z",
     "shell.execute_reply.started": "2025-05-30T21:31:46.383632Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Экскурсия прошла великолепно , Владимир Анатольевич просто изумительный экскурсовод .',\n",
       " ['Экскурсия прошла великолепно , Владимир Анатольевич просто изумительный экскурсовод .',\n",
       "  'Экскурсия прошла великолепно , Владимир Анатольевич просто великолепный экскурсовод .',\n",
       "  'Экскурсия прошла великолепно , Владимир Анатольевич просто удивительный экскурсовод .',\n",
       "  'Экскурсия прошла прекрасно , Владимир Анатольевич просто изумительный экскурсовод .',\n",
       "  'Экскурсия прошла великолепно , Владимир Анатольевич просто изумительный гидовод .',\n",
       "  'Экскурсия прошла великолепно , Владимир Анатольевич просто замечательный экскурсовод .'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupt_corrected_pairs = [each for each in zip(KeyDataset(test_ds, 'corrupt_sent'), cors)]\n",
    "# corrupt_corrected_pairs = [[each[0], each[1]] for each in corrupt_corrected_pairs]\n",
    "corrupt_corrected_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "909b2733-9e53-46ef-ba8d-0dff53267e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T12:54:03.730928Z",
     "iopub.status.busy": "2025-05-30T12:54:03.730068Z",
     "iopub.status.idle": "2025-05-30T12:54:03.763475Z",
     "shell.execute_reply": "2025-05-30T12:54:03.762799Z",
     "shell.execute_reply.started": "2025-05-30T12:54:03.730895Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corrected_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57bd6c53-a117-4431-9f44-f9e1f0c4ab1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:31:46.512543Z",
     "iopub.status.busy": "2025-05-30T21:31:46.511800Z",
     "iopub.status.idle": "2025-05-30T21:31:46.523331Z",
     "shell.execute_reply": "2025-05-30T21:31:46.522587Z",
     "shell.execute_reply.started": "2025-05-30T21:31:46.512517Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Экскурсия прошла великолепно , Владимир Анатольевич просто изумительный экскурсовод .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rulec_test.iloc[0]['correct_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d463e6-667f-4f9f-bfc7-2545c33c959f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:31:46.525164Z",
     "iopub.status.busy": "2025-05-30T21:31:46.524152Z",
     "iopub.status.idle": "2025-05-30T21:31:46.541849Z",
     "shell.execute_reply": "2025-05-30T21:31:46.541144Z",
     "shell.execute_reply.started": "2025-05-30T21:31:46.525127Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupt</th>\n",
       "      <th>hypotheses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Экскурсия прошла великолепно , Владимир Анатол...</td>\n",
       "      <td>[Экскурсия прошла великолепно , Владимир Анато...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Курсовая может быть о любой теме , которую обс...</td>\n",
       "      <td>[Курсовая может быть о любой теме , которую об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Я вижу , я слышу всё вокруг меня .</td>\n",
       "      <td>[Я вижу , я слышу всё вокруг меня ., Я вижу , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Служить в Российской армии ( для мужчин )</td>\n",
       "      <td>[Служить в Российской армии ( для мужчин ), Сл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Вряд ли все мир обеспокоился бы из-за бунта в ...</td>\n",
       "      <td>[Вряд ли весь мир обеспокоился бы из-за бунта ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             corrupt  \\\n",
       "0  Экскурсия прошла великолепно , Владимир Анатол...   \n",
       "1  Курсовая может быть о любой теме , которую обс...   \n",
       "2                 Я вижу , я слышу всё вокруг меня .   \n",
       "3          Служить в Российской армии ( для мужчин )   \n",
       "4  Вряд ли все мир обеспокоился бы из-за бунта в ...   \n",
       "\n",
       "                                          hypotheses  \n",
       "0  [Экскурсия прошла великолепно , Владимир Анато...  \n",
       "1  [Курсовая может быть о любой теме , которую об...  \n",
       "2  [Я вижу , я слышу всё вокруг меня ., Я вижу , ...  \n",
       "3  [Служить в Российской армии ( для мужчин ), Сл...  \n",
       "4  [Вряд ли весь мир обеспокоился бы из-за бунта ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(corrupt_corrected_pairs, columns=['corrupt', 'hypotheses'])\n",
    "# df.hypotheses = df.hypotheses.map(lambda x: [x]) # in case there's only one output\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a5243b0-ac55-43ea-b8e4-bbfc30058348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-30T21:31:46.543813Z",
     "iopub.status.busy": "2025-05-30T21:31:46.542710Z",
     "iopub.status.idle": "2025-05-30T21:31:46.632015Z",
     "shell.execute_reply": "2025-05-30T21:31:46.631172Z",
     "shell.execute_reply.started": "2025-05-30T21:31:46.543784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('dev_results/finetune_rugec_Ae_mult.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b5940-dcbf-4890-88ad-55d2123dd80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
